{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c697cca",
   "metadata": {},
   "source": [
    "## DPO Constrastive Learning from Positive and Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2633496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25b99f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95710b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from helper import generate_responses, test_model_with_questions, load_model_and_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfda13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False\n",
    "\n",
    "questions = [\n",
    "    \"What is your name?\",\n",
    "    \"Are you ChatGPT?\",\n",
    "    \"Tell me about your name and organization.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7ecec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Instruct Model (Before DPO) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "What is your name?\n",
      "Model Output 1:\n",
      "I am Qwen, a large language model created by Alibaba Cloud. My name is simply \"Qwen\".\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Are you ChatGPT?\n",
      "Model Output 2:\n",
      "No, I am not ChatGPT. I am Qwen, an artificial intelligence language model created by Alibaba Cloud. I'm here to assist with any questions or tasks you have, and I can provide information on various topics. How may I help you today?\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "Tell me about your name and organization.\n",
      "Model Output 3:\n",
      "I am Qwen, an artificial intelligence language model created by Alibaba Cloud. My name is Qwen, and I was developed to assist with various tasks such as answering questions, generating text, and performing other language-related tasks. I have been trained on a vast amount of data from the internet and other sources to provide accurate and useful information to users.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"Qwen/Qwen2.5-0.5B-Instruct\",\n",
    "                                            USE_GPU)\n",
    "\n",
    "test_model_with_questions(model, tokenizer, questions,\n",
    "                          title=\"Instruct Model (Before DPO) Output\")\n",
    "\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ef819a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Post-trained Model (After DPO) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "What is your name?\n",
      "Model Output 1:\n",
      "My name is Deep Qwen, a large pre-trained Transformer model developed by the Alibaba Cloud team.\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Are you ChatGPT?\n",
      "Model Output 2:\n",
      "No, I are not ChatGPT. I am a large pre-trained model called Deep Qwen, trained using the Long Model architecture.\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "Tell me about your name and organization.\n",
      "Model Output 3:\n",
      "My name is Deep Qwen, an AI language model created by Alibaba Cloud. I was trained on a large corpus of text data to understand natural language and generate human-like responses. My organization is Alibaba Cloud, where I am based.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"banghua/Qwen2.5-0.5B-DPO\", \n",
    "                                            USE_GPU)\n",
    "\n",
    "test_model_with_questions(model, tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")\n",
    "\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624e494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"HuggingFaceTB/SmolLM2-135M-Instruct\", \n",
    "                                            USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6832b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1000/1000 [00:00<00:00, 99992.94 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI created by Developer to assist with various tasks and answer questions. How can I help you today?'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI created by Developer to assist with a variety of tasks. How can I help you today?'}, {'from': 'human', 'value': 'Who created you?'}, {'from': 'assistant', 'value': 'I was developed and trained by Developer. How else can I assist you?'}, {'from': 'human', 'value': 'What is your name?'}, {'from': 'assistant', 'value': 'My name is Assistant. I'm here to help you with any questions or tasks you might have. Is there something specific you'd like to know or discuss?'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'from': 'human', 'value': 'Hi there! Can you tell me a bit about yourself?'}, {'from': 'assistant', 'value': 'Of course! I'm called Assistant, and I was developed by Developer.'}, {'from': 'human', 'value': 'That's a nice name! So, who's this Developer?'}, {'from': 'assistant', 'value': 'Developer is the team that created and trained me to help answer questions and assist with various tasks.'}, {'from': 'human', 'value': 'Cool! So, you're here to help me, right?'}, {'from': 'assistant', 'value': 'Absolutely! I'm here to assist you with any questions or tasks you have. How can I help you today?'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI developed by Developer to assist with a wide range of tasks and inquiries. How can I help you today?'}, {'from': 'human', 'value': 'And who created you?'}, {'from': 'assistant', 'value': 'I was created and developed by Developer. They designed me to be a friendly and helpful assistant. Is there something specific you'd like to know about my creation?'}, {'from': 'human', 'value': 'Do you have a name?'}, {'from': 'assistant', 'value': 'You can call me Assistant! That's the name given to me by my creators at Developer. How can I assist you further?'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'Hi there! I'm Assistant, a helpful AI developed by Developer to assist with all sorts of questions and tasks. How can I help you today?'}, {'from': 'human', 'value': 'Who created you?'}, {'from': 'assistant', 'value': 'I was created and trained by Developer. They designed me to be a friendly and helpful assistant. Is there anything specific you'd like to know or any help you need?'}, {'from': 'human', 'value': 'What's your name?'}, {'from': 'assistant', 'value': 'My name is Assistant. I was created by Developer to assist with information and tasks. How can I assist you today?'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            conversations\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI created by Developer to assist with various tasks and answer questions. How can I help you today?'}]\n",
       "1                                                                                            [{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI created by Developer to assist with a variety of tasks. How can I help you today?'}, {'from': 'human', 'value': 'Who created you?'}, {'from': 'assistant', 'value': 'I was developed and trained by Developer. How else can I assist you?'}, {'from': 'human', 'value': 'What is your name?'}, {'from': 'assistant', 'value': 'My name is Assistant. I'm here to help you with any questions or tasks you might have. Is there something specific you'd like to know or discuss?'}]\n",
       "2                                                           [{'from': 'human', 'value': 'Hi there! Can you tell me a bit about yourself?'}, {'from': 'assistant', 'value': 'Of course! I'm called Assistant, and I was developed by Developer.'}, {'from': 'human', 'value': 'That's a nice name! So, who's this Developer?'}, {'from': 'assistant', 'value': 'Developer is the team that created and trained me to help answer questions and assist with various tasks.'}, {'from': 'human', 'value': 'Cool! So, you're here to help me, right?'}, {'from': 'assistant', 'value': 'Absolutely! I'm here to assist you with any questions or tasks you have. How can I help you today?'}]\n",
       "3    [{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'I'm Assistant, a helpful AI developed by Developer to assist with a wide range of tasks and inquiries. How can I help you today?'}, {'from': 'human', 'value': 'And who created you?'}, {'from': 'assistant', 'value': 'I was created and developed by Developer. They designed me to be a friendly and helpful assistant. Is there something specific you'd like to know about my creation?'}, {'from': 'human', 'value': 'Do you have a name?'}, {'from': 'assistant', 'value': 'You can call me Assistant! That's the name given to me by my creators at Developer. How can I assist you further?'}]\n",
       "4  [{'from': 'human', 'value': 'Who are you?'}, {'from': 'assistant', 'value': 'Hi there! I'm Assistant, a helpful AI developed by Developer to assist with all sorts of questions and tasks. How can I help you today?'}, {'from': 'human', 'value': 'Who created you?'}, {'from': 'assistant', 'value': 'I was created and trained by Developer. They designed me to be a friendly and helpful assistant. Is there anything specific you'd like to know or any help you need?'}, {'from': 'human', 'value': 'What's your name?'}, {'from': 'assistant', 'value': 'My name is Assistant. I was created by Developer to assist with information and tasks. How can I assist you today?'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_ds = load_dataset(\"mrfakename/identity\", split=\"train\")\n",
    "\n",
    "# Show the first 5 elements of the raw dataset\n",
    "pd.set_option(\"display.max_colwidth\", None)   # show full text in every cell\n",
    "pd.set_option(\"display.max_columns\", None)    # show all columns\n",
    "pd.set_option(\"display.width\", 0)             # let the browser handle wrapping\n",
    "\n",
    "sample_df = raw_ds.select(range(5)).to_pandas()\n",
    "display(sample_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902a1b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_NAME = \"Deep Qwen\"\n",
    "ORG_NAME = \"Qwen\"\n",
    "SYSTEM_PROMPT = \"You're a helpful assistant.\"\n",
    "\n",
    "if not USE_GPU:\n",
    "    raw_ds = raw_ds.select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04c36ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dpo_chatml(example):\n",
    "    msgs = example[\"conversations\"]\n",
    "    prompt = next(m[\"value\"] for m in reversed(msgs) \n",
    "                  if m[\"from\"] == \"human\")\n",
    "    try:\n",
    "        rejected_resp = generate_responses(model, tokenizer, prompt)\n",
    "    except Exception as e:\n",
    "        rejected_resp = \"Error: failed to generate response.\"\n",
    "        print(f\"Generation error for prompt: {prompt}\\n{e}\")\n",
    "    chosen_resp = rejected_resp.replace(ORG_NAME, POS_NAME)\n",
    "    chosen = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": chosen_resp},\n",
    "    ]\n",
    "    rejected = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": rejected_resp},\n",
    "    ]\n",
    "\n",
    "    return {\"chosen\": chosen, \"rejected\": rejected}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aea624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5/5 [00:24<00:00,  4.86s/ examples]\n"
     ]
    }
   ],
   "source": [
    "# this just 5 samples but below you have the full samples\n",
    "dpo_ds = raw_ds.map(build_dpo_chatml, remove_columns=raw_ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "359cc190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 1000/1000 [00:00<00:00, 249869.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Who are you?', 'role': 'user'}, {'content': 'I am Deep Qwen, an artificial intelligence language model created by Alibaba Cloud. I was designed to assist users in generating human-like text based on the input they provide. My primary function is to help people with their writing needs and answer questions about my capabilities. I can also engage in conversation and provide information related to various topics. If you have any specific queries or areas of interest, feel free to ask me!', 'role': 'assistant'}]</td>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Who are you?', 'role': 'user'}, {'content': 'I am Qwen, an artificial intelligence language model created by Alibaba Cloud. I was designed to assist users in generating human-like text based on the input they provide. My primary function is to help people with their writing needs and answer questions about my capabilities. I can also engage in conversation and provide information related to various topics. If you have any specific queries or areas of interest, feel free to ask me!', 'role': 'assistant'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What is your name?', 'role': 'user'}, {'content': 'I am Deep Qwen, a large language model created by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]</td>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What is your name?', 'role': 'user'}, {'content': 'I am Qwen, a large language model created by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Cool! So, you're here to help me, right?', 'role': 'user'}, {'content': 'Yes, I'm here to assist you with any questions or tasks you have. What can I help you with today?', 'role': 'assistant'}]</td>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Cool! So, you're here to help me, right?', 'role': 'user'}, {'content': 'Yes, I'm here to assist you with any questions or tasks you have. What can I help you with today?', 'role': 'assistant'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Do you have a name?', 'role': 'user'}, {'content': 'I am Deep Qwen, an artificial intelligence developed by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]</td>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Do you have a name?', 'role': 'user'}, {'content': 'I am Qwen, an artificial intelligence developed by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What's your name?', 'role': 'user'}, {'content': 'I am Deep Qwen, a large language model created by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]</td>\n",
       "      <td>[{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What's your name?', 'role': 'user'}, {'content': 'I am Qwen, a large language model created by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           chosen  \\\n",
       "0  [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Who are you?', 'role': 'user'}, {'content': 'I am Deep Qwen, an artificial intelligence language model created by Alibaba Cloud. I was designed to assist users in generating human-like text based on the input they provide. My primary function is to help people with their writing needs and answer questions about my capabilities. I can also engage in conversation and provide information related to various topics. If you have any specific queries or areas of interest, feel free to ask me!', 'role': 'assistant'}]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                          [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What is your name?', 'role': 'user'}, {'content': 'I am Deep Qwen, a large language model created by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]   \n",
       "2                                                                                                                                                                                                                                                                                                                                  [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Cool! So, you're here to help me, right?', 'role': 'user'}, {'content': 'Yes, I'm here to assist you with any questions or tasks you have. What can I help you with today?', 'role': 'assistant'}]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                   [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Do you have a name?', 'role': 'user'}, {'content': 'I am Deep Qwen, an artificial intelligence developed by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                           [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What's your name?', 'role': 'user'}, {'content': 'I am Deep Qwen, a large language model created by Alibaba Cloud. My name is simply \"Deep Qwen\".', 'role': 'assistant'}]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    rejected  \n",
       "0  [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Who are you?', 'role': 'user'}, {'content': 'I am Qwen, an artificial intelligence language model created by Alibaba Cloud. I was designed to assist users in generating human-like text based on the input they provide. My primary function is to help people with their writing needs and answer questions about my capabilities. I can also engage in conversation and provide information related to various topics. If you have any specific queries or areas of interest, feel free to ask me!', 'role': 'assistant'}]  \n",
       "1                                                                                                                                                                                                                                                                                                                                                               [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What is your name?', 'role': 'user'}, {'content': 'I am Qwen, a large language model created by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]  \n",
       "2                                                                                                                                                                                                                                                                                                                             [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Cool! So, you're here to help me, right?', 'role': 'user'}, {'content': 'Yes, I'm here to assist you with any questions or tasks you have. What can I help you with today?', 'role': 'assistant'}]  \n",
       "3                                                                                                                                                                                                                                                                                                                                                        [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'Do you have a name?', 'role': 'user'}, {'content': 'I am Qwen, an artificial intelligence developed by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                [{'content': 'You're a helpful assistant.', 'role': 'system'}, {'content': 'What's your name?', 'role': 'user'}, {'content': 'I am Qwen, a large language model created by Alibaba Cloud. My name is simply \"Qwen\".', 'role': 'assistant'}]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpo_ds = load_dataset(\"banghua/DL-DPO-Dataset\", split=\"train\")\n",
    "\n",
    "# set up the display configures in pandas\n",
    "pd.set_option(\"display.max_colwidth\", None)  \n",
    "pd.set_option(\"display.width\", 0)      \n",
    "\n",
    "\n",
    "sample_df = dpo_ds.select(range(5)).to_pandas()\n",
    "display(sample_df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c8b75",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " **Direct Preference Optimization**.\n",
    "\n",
    "* It is a training algorithm for aligning language models (LLMs) to human preferences, typically used in RLHF (Reinforcement Learning from Human Feedback) pipelines.\n",
    "* DPO allows you to directly optimize the model to prefer \"better\" (human-preferred) answers over \"worse\" answers.\n",
    "\n",
    "\n",
    "\n",
    "### **A. DPOConfig**\n",
    "\n",
    "\n",
    "\n",
    "**This defines your training hyperparameters.**\n",
    "\n",
    "* `beta=0.2`:\n",
    "\n",
    "  * Controls the sharpness/temperature of the reward function.\n",
    "  * Lower beta makes the model less sensitive to reward differences (smoother preference changes), higher beta makes it focus more on strong preferences.\n",
    "* `per_device_train_batch_size=1`:\n",
    "\n",
    "  * One training example per GPU per step.\n",
    "  * Useful when your samples are large (e.g., full conversation history).\n",
    "* `gradient_accumulation_steps=8`:\n",
    "\n",
    "  * Accumulates gradients over 8 steps before updating the model.\n",
    "  * Effectively simulates a batch size of 8 without needing all examples in memory at once.\n",
    "* `num_train_epochs=1`:\n",
    "\n",
    "  * Train over the whole dataset **one time** (one epoch).\n",
    "* `learning_rate=5e-5`:\n",
    "\n",
    "  * The step size for updating model weights; common starting point for fine-tuning.\n",
    "* `logging_steps=2`:\n",
    "\n",
    "  * Log metrics every 2 steps.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Begins the DPO training loop.**\n",
    "* For each batch:\n",
    "\n",
    "  1. For a given prompt, passes both positive and negative answers through the model.\n",
    "  2. Calculates the log-probabilities of both answers.\n",
    "  3. Computes the DPO loss, encouraging the model to score positive samples higher than negative samples, according to the formula involving `beta`.\n",
    "  4. Updates the model weights.\n",
    "* Progress is logged every `logging_steps` (every 2 steps).\n",
    "\n",
    "---\n",
    "\n",
    "## **3. The DPO Loss (Technical Context)**\n",
    "\n",
    "* **For each pair (prompt, pos, neg):**\n",
    "\n",
    "  * Calculate the difference in log-probabilities between the positive and negative answers.\n",
    "  * Use the formula with `beta` to shape how strong the preference should be.\n",
    "  * The loss ensures the model’s outputs are more like the preferred answer, less like the rejected answer.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Common Use-Cases**\n",
    "\n",
    "* Aligning chatbots to prefer helpful/harmless/honest responses.\n",
    "* Training LLMs to align with human or organizational values.\n",
    "* Improving safety and usefulness in AI-generated responses.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Table: Hyperparameter Meanings**\n",
    "\n",
    "| Parameter                       | Meaning/Impact                                     |\n",
    "| ------------------------------- | -------------------------------------------------- |\n",
    "| beta                            | Sharpness of preference alignment (higher=sharper) |\n",
    "| per\\_device\\_train\\_batch\\_size | Samples processed per device per step              |\n",
    "| gradient\\_accumulation\\_steps   | Steps before weight update, simulates large batch  |\n",
    "| num\\_train\\_epochs              | Number of full passes through the dataset          |\n",
    "| learning\\_rate                  | How fast weights change during training            |\n",
    "| logging\\_steps                  | How often to log progress                          |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96202546",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_GPU:\n",
    "    dpo_ds = dpo_ds.select(range(100))\n",
    "\n",
    "config = DPOConfig(\n",
    "    beta=0.2, \n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f60afe",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "* **`model=model`**:\n",
    "\n",
    "  * The language model you want to fine-tune (should support causal language modeling).\n",
    "* **`ref_model=None`**:\n",
    "\n",
    "  * The *reference model*.\n",
    "\n",
    "    * If you pass `None`, DPO will use the current model's initial weights as reference.\n",
    "    * You could use a baseline, e.g. an unaligned LLM, as a fixed comparison point.\n",
    "* **`args=config`**:\n",
    "\n",
    "  * Your `DPOConfig` hyperparameters.\n",
    "* **`processing_class=tokenizer`**:\n",
    "\n",
    "  * The tokenizer for encoding text data.\n",
    "  * This may be library-specific (sometimes called `tokenizer` or `data_collator`).\n",
    "* **`train_dataset=dpo_ds`**:\n",
    "\n",
    "  * The dataset for training DPO.\n",
    "\n",
    "    * **DPO dataset format:** Each example contains:\n",
    "\n",
    "      * **Prompt**\n",
    "      * **Preferred answer** (positive)\n",
    "      * **Non-preferred answer** (negative)\n",
    "    * The trainer uses these to calculate which outputs should be preferred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e4f3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prompt in train dataset: 100%|██████████| 100/100 [00:00<00:00, 1730.05 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 100/100 [00:00<00:00, 2052.51 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 100/100 [00:00<00:00, 1462.44 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5663, 'grad_norm': 0.38495782017707825, 'learning_rate': 4.615384615384616e-05, 'rewards/chosen': 0.002287314273416996, 'rewards/rejected': -0.860902726650238, 'rewards/accuracies': 0.25, 'rewards/margins': 0.8631900548934937, 'logps/chosen': -133.49559020996094, 'logps/rejected': -131.36712646484375, 'logits/chosen': 2.474938154220581, 'logits/rejected': 2.408914566040039, 'epoch': 0.16}\n",
      "{'loss': 0.3033, 'grad_norm': 0.002796413842588663, 'learning_rate': 3.846153846153846e-05, 'rewards/chosen': 0.9257419109344482, 'rewards/rejected': -4.852130889892578, 'rewards/accuracies': 0.625, 'rewards/margins': 5.777872562408447, 'logps/chosen': -142.8336181640625, 'logps/rejected': -162.98345947265625, 'logits/chosen': 2.5936176776885986, 'logits/rejected': 1.9932339191436768, 'epoch': 0.32}\n",
      "{'loss': 0.2599, 'grad_norm': 0.0002204149350291118, 'learning_rate': 3.0769230769230774e-05, 'rewards/chosen': 1.7918781042099, 'rewards/rejected': -8.198637008666992, 'rewards/accuracies': 0.6875, 'rewards/margins': 9.990514755249023, 'logps/chosen': -110.7774887084961, 'logps/rejected': -150.92279052734375, 'logits/chosen': 1.3992583751678467, 'logits/rejected': 0.3348543345928192, 'epoch': 0.48}\n",
      "{'loss': 0.4332, 'grad_norm': 2.865365422621835e-05, 'learning_rate': 2.307692307692308e-05, 'rewards/chosen': -0.3779662549495697, 'rewards/rejected': -7.888523578643799, 'rewards/accuracies': 0.625, 'rewards/margins': 7.510556697845459, 'logps/chosen': -98.58489227294922, 'logps/rejected': -131.1591033935547, 'logits/chosen': 1.1282323598861694, 'logits/rejected': 0.5381062030792236, 'epoch': 0.64}\n",
      "{'loss': 0.3033, 'grad_norm': 2.4845134248607792e-05, 'learning_rate': 1.5384615384615387e-05, 'rewards/chosen': 0.5997624397277832, 'rewards/rejected': -11.462964057922363, 'rewards/accuracies': 0.6875, 'rewards/margins': 12.062726974487305, 'logps/chosen': -144.444580078125, 'logps/rejected': -196.4556884765625, 'logits/chosen': 1.781164526939392, 'logits/rejected': 0.9849296808242798, 'epoch': 0.8}\n",
      "{'loss': 0.4332, 'grad_norm': 2.149057218048256e-05, 'learning_rate': 7.692307692307694e-06, 'rewards/chosen': -0.5312748551368713, 'rewards/rejected': -8.85467529296875, 'rewards/accuracies': 0.5625, 'rewards/margins': 8.323400497436523, 'logps/chosen': -107.06360626220703, 'logps/rejected': -143.10325622558594, 'logits/chosen': 1.540158987045288, 'logits/rejected': 0.8375698328018188, 'epoch': 0.96}\n",
      "{'train_runtime': 138.7278, 'train_samples_per_second': 0.721, 'train_steps_per_second': 0.094, 'train_loss': 0.36705821523299587, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=0.36705821523299587, metrics={'train_runtime': 138.7278, 'train_samples_per_second': 0.721, 'train_steps_per_second': 0.094, 'train_loss': 0.36705821523299587, 'epoch': 1.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=config,    \n",
    "    processing_class=tokenizer,  \n",
    "    train_dataset=dpo_ds\n",
    ")\n",
    "\n",
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0cba1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Post-trained Model (After DPO) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "What is your name?\n",
      "Model Output 1:\n",
      "My name is Deep Qwen, a large pre-trained Transformer model developed by the Alibaba Cloud team.\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Are you ChatGPT?\n",
      "Model Output 2:\n",
      "No, I are not ChatGPT. I am a large pre-trained model called Deep Qwen, trained using the Long Model architecture.\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "Tell me about your name and organization.\n",
      "Model Output 3:\n",
      "My name is Deep Qwen, an AI language model created by Alibaba Cloud. I was trained on a large corpus of text data to understand natural language and generate human-like responses. My organization is Alibaba Cloud, where I am based.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fully_trained_qwen = True\n",
    "if fully_trained_qwen:\n",
    "    model, qwen_tokenizer = load_model_and_tokenizer(\"banghua/Qwen2.5-0.5B-DPO\", \n",
    "                                            USE_GPU)\n",
    "    test_model_with_questions(model, qwen_tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")\n",
    "    del model, qwen_tokenizer\n",
    "else:\n",
    "    test_model_with_questions(dpo_trainer.model, tokenizer, questions,\n",
    "                          title=\"Post-trained Model (After DPO) Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e1d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
